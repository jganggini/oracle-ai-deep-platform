# MinerU OCR Docker

Servicio Docker optimizado para MinerU OCR con procesamiento paralelo por pÃ¡gina, soporte GPU parametrizable por VRAM, y concurrencia configurable para mÃ¡ximo rendimiento.

## ğŸš€ **CaracterÃ­sticas Principales**

- âœ… **Procesamiento por pÃ¡gina**: Divide PDFs y procesa cada pÃ¡gina individualmente
- âœ… **Concurrencia configurable**: Escala segÃºn GPU/VRAM y CPU disponibles
- âœ… **VRAM parametrizable**: Ajustable por entorno segÃºn los recursos del host
- âœ… **PaginaciÃ³n automÃ¡tica**: Genera Markdown con encabezados y marcadores por pÃ¡gina
- âœ… **Estructura organizada**: ZIP con `upload.md`, `images/` y `pages/` individuales
- âœ… **Optimizaciones de hilos**: Evita contenciÃ³n con lÃ­mites de threads por proceso

## ğŸ“Š **Pruebas de rendimiento**

Tabla de resultados por ejecuciÃ³n:

| EjecuciÃ³n | Tiempo (s) | Concurrencia | VRAM (MB) |
|-----------|------------|--------------|-----------|
| 2GB/10x Run 1 | 96.73 | 10 | 2048 |
| 2GB/10x Run 2 | 97.07 | 10 | 2048 |
| 2GB/10x Run 3 | 94.28 | 10 | 2048 |
| 4GB/5x Run 1  | 52.66 | 5  | 4096 |
| 4GB/5x Run 2  | 50.61 | 5  | 4096 |
| 4GB/5x Run 3  | 51.70 | 5  | 4096 |
| 8GB/2x Run 1  | 96.01 | 2  | 8192 |
| 8GB/2x Run 2  | 98.62 | 2  | 8192 |
| 8GB/2x Run 3  | 95.13 | 2  | 8192 |

Notas:
- El primer run de un escenario puede ser mÃ¡s lento por descarga/caliente de modelos; los siguientes usan cachÃ©.
- Hay archivos de ejemplo para pruebas en: [`test-ocr.ps1`](./_test/test-ocr.ps1) y [`test-ocr.sh`](./_test/test-ocr.sh).
- Los tiempos varÃ­an segÃºn hardware, drivers y tipo de documento.

## ğŸš€ **InstalaciÃ³n RÃ¡pida**

### 1. Configurar variables de entorno
```bash
cp env.example .env
# Editar .env para ajustar concurrencia y VRAM segÃºn tu GPU
```

### 2. Construir y ejecutar
```bash
# Construir imagen optimizada
docker compose build

# Ejecutar servicio
docker compose up -d
```

### 3. Verificar funcionamiento
```bash
# Verificar estado
docker compose ps

# Probar endpoint principal
curl http://localhost:8001/
```

## ğŸ“ **Estructura del Proyecto**

```
docker-mineru/
â”œâ”€â”€ main.py              # API FastAPI optimizada
â”œâ”€â”€ requirements.txt     # Dependencias Python con PyTorch CUDA
â”œâ”€â”€ Dockerfile.mineru   # Dockerfile con soporte GPU NVIDIA
â”œâ”€â”€ docker-compose.yaml  # ConfiguraciÃ³n Docker con lÃ­mites de recursos
â”œâ”€â”€ env.example         # Variables de entorno de ejemplo
â”œâ”€â”€ models/             # Directorio para modelos (se crea automÃ¡ticamente)
â”œâ”€â”€ cache/              # Directorio para cache (se crea automÃ¡ticamente)
â””â”€â”€ data/               # Directorio para archivos de entrada (se crea automÃ¡ticamente)
```

## ğŸ”§ **ConfiguraciÃ³n**

### Variables de Entorno (.env)
```ini
# Puerto principal
MINERU_PORT=8001

# GPU
GPU_ENABLED=true
GPU_DEVICE=cuda
GPU_BACKEND=pipeline

# Optimizaciones de hilos
OMP_NUM_THREADS=1
MKL_NUM_THREADS=1
OPENBLAS_NUM_THREADS=1
NUMEXPR_NUM_THREADS=1

# Rutas de cachÃ© y modelos
CACHE_DIR=/app/cache
MODEL_PATH=/app/models
```

### **VRAM y concurrencia**

- La aplicaciÃ³n es flexible: ajusta concurrencia y VRAM segÃºn tu hardware.
- La concurrencia efectiva depende de la memoria GPU, CPU y velocidad de disco.
- El archivo `env.example` es solo una referencia; no impone lÃ­mites.

## ğŸ“– **Uso del Servicio**

### **Ejemplo de OCR con campos de formulario (recomendado)**
```powershell
# PowerShell (Windows)
$Form = @{
  file        = Get-Item "C:\file.pdf"
  vram_limit  = "2048"      # MB por proceso
  concurrency = "10"        # pÃ¡ginas en paralelo
  use_gpu     = "true"
  device      = "cuda"
  backend     = "pipeline"
}
Invoke-WebRequest -Uri "http://localhost:8001/ocr" -Method POST -Form $Form -OutFile "D:\Downloads\ocr_result.zip"
```

```bash
# Bash/Linux/macOS
curl -X POST "http://localhost:8001/ocr" \
  -F "file=@/ruta/a/doc.pdf" \
  -F "vram_limit=2048" \
  -F "concurrency=10" \
  -F "use_gpu=true" \
  -F "device=cuda" \
  -F "backend=pipeline" -o upload.zip
```

### **Ejemplo alternativo con Invoke-WebRequest (PowerShell 7+)**
```powershell
$Form = @{
  file        = Get-Item "C:\doc.pdf"
  vram_limit  = "2048"
  concurrency = "10"
  use_gpu     = "true"
  device      = "cuda"
  backend     = "pipeline"
}
$sw=[System.Diagnostics.Stopwatch]::StartNew()
Invoke-WebRequest -Uri "http://localhost:8001/ocr" -Method POST -Form $Form -OutFile "D:\Downloads\ocr_result.zip"
$sw.Stop()
Write-Output ("Procesado en " + [Math]::Round($sw.Elapsed.TotalSeconds,2) + " s")
```

### **Estructura del ZIP Resultante**
```
upload.zip
â”œâ”€â”€ upload.md              # Markdown consolidado con paginaciÃ³n
â”œâ”€â”€ images/                # ImÃ¡genes extraÃ­das por pÃ¡gina
â”‚   â”œâ”€â”€ p1_imagen1.jpg
â”‚   â”œâ”€â”€ p2_imagen2.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ pages/                 # ZIPs individuales por pÃ¡gina
    â”œâ”€â”€ page_0001.zip
    â”œâ”€â”€ page_0002.zip
    â””â”€â”€ ...
```

### **Formato del Markdown Generado**
```markdown
## PÃ¡gina 1 <a id="p1"></a>

# TÃ­tulo del documento

Contenido del primer pÃ¡rrafo [p1](#p1)

## PÃ¡gina 2 <a id="p2"></a>

Contenido de la segunda pÃ¡gina [p2](#p2)
```

## ğŸ³ **Comandos Docker Ãštiles**

```bash
# Ver logs en tiempo real
docker compose logs -f

# Reiniciar servicio
docker compose restart

# Parar servicio
docker compose down

# Reconstruir despuÃ©s de cambios
docker compose up -d --build

# Ejecutar con configuraciÃ³n personalizada
MINERU_CONCURRENCY=3 VRAM_LIMIT=2048 docker compose up -d

# Verificar uso de recursos
docker stats mineru-ocr
```

## ğŸ” **Troubleshooting y Monitoreo**

### **Verificar logs del servicio**
```bash
docker compose logs mineru
```

### **Verificar estado del contenedor**
```bash
docker compose ps
docker exec -it mineru-ocr bash
```

### **Verificar GPU y VRAM**
```bash
# Dentro del contenedor
nvidia-smi
python3 -c "import torch; print(f'CUDA disponible: {torch.cuda.is_available()}'); print(f'VRAM total: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')"
```

### **Monitorear rendimiento**
```bash
# Ver uso de CPU y memoria
docker stats mineru-ocr

# Ver logs de procesamiento
docker compose logs -f --tail=100
```

## âš¡ **Optimizaciones Implementadas**

### **1. Procesamiento Paralelo por PÃ¡gina**
- DivisiÃ³n automÃ¡tica del PDF en pÃ¡ginas individuales
- EjecuciÃ³n concurrente de MinerU por pÃ¡gina
- SemÃ¡foro configurable para controlar concurrencia

### **2. LÃ­mites de Hilos por Proceso**
- `OMP_NUM_THREADS=1`: Evita contenciÃ³n de OpenMP
- `MKL_NUM_THREADS=1`: Optimiza Intel MKL
- `OPENBLAS_NUM_THREADS=1`: Controla OpenBLAS
- `NUMEXPR_NUM_THREADS=1`: Limita NumExpr

### **3. GestiÃ³n Eficiente de Memoria**
- VRAM parametrizable para mejor distribuciÃ³n
- Procesamiento por streaming para archivos grandes
- Limpieza automÃ¡tica de archivos temporales

### **4. Estructura de Salida Organizada**
- Markdown consolidado con paginaciÃ³n automÃ¡tica
- ImÃ¡genes organizadas por pÃ¡gina con prefijos
- ZIPs individuales por pÃ¡gina para anÃ¡lisis detallado

## ğŸ“ **Casos de Uso Recomendados**

### **Ideal para:**
- âœ… PDFs de 10-50 pÃ¡ginas
- âœ… GPUs de 4GB o mÃ¡s (escala con VRAM)
- âœ… Procesamiento en lote de documentos
- âœ… AnÃ¡lisis de documentos estructurados
- âœ… ExtracciÃ³n de texto con contexto de pÃ¡gina

### **Considerar alternativas para:**
- âŒ PDFs muy largos (>100 pÃ¡ginas) - usar procesamiento por lotes
- âŒ GPUs con <4GB VRAM - reducir concurrencia
- âŒ Tiempo real crÃ­tico - usar procesamiento sÃ­ncrono

## ğŸ”§ **Ajustes de Rendimiento**

- Aumenta `MINERU_CONCURRENCY` y `VRAM_LIMIT` segÃºn recursos.
- Con mÃ¡s GPU/VRAM/CPU, el servicio escala para mayores cargas.

## ğŸ”— **Referencias y DocumentaciÃ³n**

- [MinerU GitHub](https://github.com/opendatalab/MinerU) - DocumentaciÃ³n oficial
- [Docker Compose](https://docs.docker.com/compose/) - GuÃ­a de Docker Compose
- [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/) - Soporte GPU
- [FastAPI](https://fastapi.tiangolo.com/) - Framework web de alto rendimiento

## ğŸ“ˆ **Roadmap Futuro**

- [ ] Soporte para procesamiento por lotes de mÃºltiples PDFs
- [ ] MÃ©tricas de rendimiento en tiempo real
- [ ] Cache inteligente de modelos para reutilizaciÃ³n
- [ ] API para monitoreo de recursos GPU/CPU
- [ ] Soporte para otros formatos de entrada (TIFF, PNG, etc.)

---

**VersiÃ³n**: 2.0.0-optimized  
**Ãšltima actualizaciÃ³n**: Diciembre 2024  
**Compatibilidad**: CUDA 12.1+, Python 3.10+, Docker 20.10+
